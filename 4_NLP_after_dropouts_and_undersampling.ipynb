{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "up5zfaqnCJb3"
   },
   "source": [
    "The fourth - after increasing dropouts and undersampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztBfBlGRlDx0",
    "outputId": "d8592d3f-fbda-4034-ec4b-b2c1f12a0baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip3 install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRV3QfOJmQvR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import EvalPrediction\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Um3nFUOtmqXL"
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"intermediate_data.xlsx\")\n",
    "final_data = pd.read_excel(\"final_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_NNG_wdDhSo"
   },
   "outputs": [],
   "source": [
    "labels = [\"Val_0\", \"Val_1\"]\n",
    "report_folder_name = \"Reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSfedblvfYZX"
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(report_folder_name):\n",
    "  os.mkdir(report_folder_name)\n",
    "else:\n",
    "  shutil.rmtree(report_folder_name)\n",
    "  os.mkdir(report_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cpv6y4M3Vir"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataframe(data_df, convert_into_binary=True):\n",
    "  if convert_into_binary:\n",
    "    data_df = pd.concat((data_df, pd.get_dummies(data_df[\"memory_change\"])), axis=1)\n",
    "    data_df = data_df.rename(columns={\"file_content\": \"text\", 0:\"Val_0\", 1:\"Val_1\"})\n",
    "    data_df.drop(list(set(data_df.columns).difference(set([\"text\", \"Val_0\", \"Val_1\"]))), inplace=True, axis=1)      \n",
    "    data_df = data_df.replace({0:False, 1: True})\n",
    "  else:\n",
    "    data_df = data_df.rename(columns={\"file_content\": \"text\", \"memory_change\": \"actual\"})\n",
    "    data_df.drop(list(set(data_df.columns).difference(set([\"text\", \"actual\"]))), inplace=True, axis=1)\n",
    "  data_df.reset_index(drop=True, inplace=True)\n",
    "  return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLREKUNXBp1T"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4Yy374mBg6Q"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"text\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text)\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwAQOzawCqqH"
   },
   "outputs": [],
   "source": [
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehMIAj1caspq"
   },
   "outputs": [],
   "source": [
    "def get_classification_report_row(classification_report):\n",
    "    data_dict = {\n",
    "                    \"Precision\": classification_report[\"weighted avg\"][\"precision\"],\n",
    "                    \"Recall\": classification_report[\"weighted avg\"][\"recall\"],\n",
    "                    \"f1-score\": classification_report[\"weighted avg\"][\"f1-score\"],\n",
    "                    \"support\": classification_report[\"weighted avg\"][\"support\"],\n",
    "                    \"Accuracy\": classification_report[\"accuracy\"]\n",
    "                }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFq03OjIJIrl"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9PJH69QEOO1"
   },
   "outputs": [],
   "source": [
    "final_data = final_data[final_data.user_id.isin(list(data[\"mapped_user_id\"]))]\n",
    "final_data_1 = final_data[final_data.memory_change==1]\n",
    "final_data_0 = final_data[final_data.memory_change==0]\n",
    "final_data_0 = final_data_0.sample(n = len(final_data_1), random_state = 42)\n",
    "final_data = pd.concat([final_data_0, final_data_1], ignore_index=True)\n",
    "data = data[data.mapped_user_id.isin(list(final_data[\"user_id\"]))]\n",
    "data = shuffle(data, random_state=42)\n",
    "final_data = shuffle(final_data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjxLS_IyFZhK"
   },
   "outputs": [],
   "source": [
    "final_data.memory_change.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEgn9sc2JUlq"
   },
   "outputs": [],
   "source": [
    "data.memory_change.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppUQ5r_7KoM_"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6q-IDfFumyJv"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "batch_size = 1\n",
    "train_epochs = 15\n",
    "metric_name = \"f1\"\n",
    "final_stat = []\n",
    "output_folder_name = f\"bert-finetuned-by-chanpreet\"\n",
    "probability_threshold = 0.5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(data[\"mapped_user_id\"], data[\"memory_change\"])):\n",
    "    train_data_user_id = list(data.iloc[train_index][\"mapped_user_id\"])\n",
    "    train_data = final_data[final_data.user_id.isin(train_data_user_id)]\n",
    "    train_data = preprocess_dataframe(train_data)\n",
    "    train_data = Dataset.from_pandas(train_data)\n",
    "\n",
    "    test_data_user_id = list(data.iloc[test_index][\"mapped_user_id\"])\n",
    "    test_data = final_data[final_data.user_id.isin(test_data_user_id)]\n",
    "    test_data_copy = deepcopy(test_data)\n",
    "    test_data = preprocess_dataframe(test_data)\n",
    "    test_data_copy = preprocess_dataframe(test_data_copy, convert_into_binary=False)\n",
    "    test_data = Dataset.from_pandas(test_data)\n",
    "\n",
    "    print(\"Fold {2}: Train size: {0}, Test size: {1}, Test range: {3}-{4}\".format(len(train_data), len(test_data), i+1, min(test_index), max(test_index)))\n",
    "    # print(test_index)\n",
    "\n",
    "    train_dataset, validation_dataset = train_data.train_test_split(test_size=0.1).values()\n",
    "    dataset = DatasetDict({\"train\": train_dataset,\n",
    "                          \"validation\": validation_dataset,\n",
    "                          \"test\": test_data\n",
    "                           })\n",
    "    encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "    labels = [label for label in dataset['train'].features.keys() if label not in [\"text\"]]\n",
    "    id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "    label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    encoded_dataset.set_format(\"torch\")\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                               num_labels=len(labels),\n",
    "                                                               id2label=id2label,\n",
    "                                                               label2id=label2id,\n",
    "                                                               attention_probs_dropout_prob=0.6, # by default it is 0.1\n",
    "                                                              #  hidden_dropout_prob=0.7\n",
    "                                                               )\n",
    "    # print(model.config)\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    args = TrainingArguments(output_folder_name,\n",
    "                             evaluation_strategy = \"epoch\",\n",
    "                             save_strategy = \"epoch\",\n",
    "                             learning_rate=2e-5,\n",
    "                             per_device_train_batch_size=batch_size,\n",
    "                             per_device_eval_batch_size=batch_size,\n",
    "                             num_train_epochs=train_epochs,\n",
    "                             weight_decay=0.01,\n",
    "                             load_best_model_at_end=True,\n",
    "                             metric_for_best_model=metric_name,\n",
    "                             #push_to_hub=True,\n",
    "                             )\n",
    "    \n",
    "    trainer = Trainer(model,\n",
    "                      args,\n",
    "                      train_dataset=encoded_dataset[\"train\"],\n",
    "                      eval_dataset=encoded_dataset[\"validation\"],\n",
    "                      tokenizer=tokenizer,\n",
    "                      compute_metrics=compute_metrics\n",
    "                      )\n",
    "    \n",
    "    trainer.train()\n",
    "    print(json.dumps(trainer.evaluate(), indent=2))\n",
    "\n",
    "    stat_list = []\n",
    "    for ind, row in test_data_copy.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "        encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "        outputs = trainer.model(**encoding)\n",
    "        logits = outputs.logits\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(logits.squeeze().cpu())\n",
    "        predictions = np.zeros(probs.shape)\n",
    "        predictions[np.where(probs >= probability_threshold)] = 1\n",
    "        # turn predicted id's into actual label names\n",
    "        predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "        if len(predicted_labels)>0:\n",
    "          stat_list.append({\"text\": text,\n",
    "                            \"actual\": row[\"actual\"],\n",
    "                            \"predicted\": int(predicted_labels[0].strip(\"Val_\"))\n",
    "                            })\n",
    "    stat_df = pd.DataFrame(stat_list)\n",
    "    stat_df.to_excel(\"{1}/{0}_fold_report.xlsx\".format(i+1, report_folder_name), index=False, header=True)\n",
    "    final_stat_dict = {\"k\": i+1,\n",
    "                       \"test_range\": \"{0}-{1}\".format(min(test_index), max(test_index))\n",
    "                      }\n",
    "    final_stat_dict.update(get_classification_report_row(classification_report(stat_df[\"actual\"], stat_df[\"predicted\"], output_dict=True)))\n",
    "    print(json.dumps(final_stat_dict, indent=2))\n",
    "    final_stat.append(final_stat_dict)\n",
    "    print(\"\\n\"*5)\n",
    "\n",
    "    for x in sorted(glob.glob(os.path.join(output_folder_name, '*/')), key=os.path.getmtime)[1:]:\n",
    "        try:\n",
    "            shutil.rmtree(x)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "\n",
    "\n",
    "final_stat_df = pd.DataFrame(final_stat)\n",
    "final_stat_df.to_excel(\"{0}/consolidated_report_{1}.xlsx\".format(report_folder_name, datetime.now().strftime(\"%Y-%m-%d_%H:%M\")), index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
