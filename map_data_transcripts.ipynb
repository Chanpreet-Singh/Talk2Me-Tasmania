{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7f72c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tfx 1.8.0 requires pyarrow<6,>=1, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "tfx-bsl 1.8.0 requires pyarrow<6,>=1, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.8.0 requires pyarrow<6,>=1, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "tensorflow-model-analysis 0.39.0 requires pyarrow<6,>=1, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "tensorflow-data-validation 1.8.0 requires pyarrow<6,>=1, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "allennlp 2.9.0 requires transformers<4.16,>=4.1, but you have transformers 4.26.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3073172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 09:52:53.659263: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:52:53.659289: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import shutil\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "from transformers import EvalPrediction\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7cafcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_folder = \"./../trans/\"\n",
    "input_file = \"data_and_corr_pvals.xlsx\"\n",
    "input_data_sheet = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b938ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_content(file_path):\n",
    "    file_content = None\n",
    "    with open(file_path, \"r\") as fp:\n",
    "        file_content = fp.read()\n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f74924",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(input_file, sheet_name=input_data_sheet)\n",
    "if \"Unnamed: 0\" in data.columns: # Removing the index column\n",
    "    data.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7781998",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"memory_change\", \"PALFAMS28Percentile\", \"mapped_user_id\"]\n",
    "data.drop(list(set(list(data.columns)).difference(set(cols_to_keep))), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec83f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 2374 files have data out of 3006\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(transcript_folder)\n",
    "relevant_files = []\n",
    "for each_file in files:\n",
    "    complete_path = \"{0}{1}\".format(transcript_folder, each_file)\n",
    "    if complete_path.endswith(\".txt\") and os.stat(complete_path).st_size > 0:\n",
    "        relevant_files.append(complete_path)\n",
    "print(\"Only {0} files have data out of {1}\".format(len(relevant_files), len(files)))\n",
    "del(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09072d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_list = []\n",
    "for each_file in relevant_files:\n",
    "    file_content = get_file_content(each_file)\n",
    "    user_id = int(each_file.split(\"_\")[2])\n",
    "    try:\n",
    "        each_data = {\n",
    "                        \"user_id\": user_id,\n",
    "                        \"file_path\": each_file,\n",
    "                        \"file_content\": file_content,\n",
    "                        \"memory_change\": data[data[\"mapped_user_id\"]==user_id][\"memory_change\"].iloc[0]\n",
    "                    }\n",
    "        final_data_list.append(each_data)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4aa2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame(final_data_list)\n",
    "if \"Unnamed: 0\" in final_data.columns: # Removing the index column\n",
    "    final_data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "del(final_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c18ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_excel(\"final_data.xlsx\", header=True, index=False)\n",
    "data.to_excel(\"intermediate_data.xlsx\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
